# ğŸ“¡ Algoritmos de NavegaciÃ³n y LocalizaciÃ³n - 2025-2 <!-- omit from toc -->

## ğŸª¶ Estudiantes: <!-- omit from toc -->
* Juan Camilo Gomez Robayo
* Andres Camilo Torres-Cajamarca

## ğŸ‘¨â€ğŸ« Profesores: <!-- omit from toc -->
* PhD. Ing. Ricardo Emiro RamÃ­rez Heredia
* PhD. Ing. Pedro Fabian CÃ¡rdenas Herrera

## ğŸ“š Indice <!-- omit from toc -->

<details>
    <summary>ğŸ—‚ï¸ Tabla de Contenido</summary>

- [1. ğŸ¯ Objetivos](#1--objetivos)
- [2. ğŸš— Conociendo al SDV](#2--conociendo-al-sdv)
  - [2.1. ğŸ§± Componentes implementados](#21--componentes-implementados)
    - [2.1.1. ğŸ›ï¸ Tiva](#211-ï¸-tiva)
    - [2.1.2. ğŸš Driver y Encoder](#212--driver-y-encoder)
    - [2.1.3. ğŸš˜ Motores](#213--motores)
    - [2.1.4. ğŸ§  NUC](#214--nuc)
    - [2.1.5. ğŸ“¶ Lidar](#215--lidar)
- [3. ğŸ”¢ Procedimiento](#3--procedimiento)
  - [3.1. ğŸ—ï¸ Arquitectura en ROS Melodic](#31-ï¸-arquitectura-en-ros-melodic)
  - [3.2. ğŸ’» Firmware de Tiva](#32--firmware-de-tiva)
  - [3.3. ğŸ¤– Arquitectura en ROS2 Humble](#33--arquitectura-en-ros2-humble)
  - [3.4. âš™ï¸ ProgramaciÃ³n de la CinemÃ¡tica del SDV](#34-ï¸-programaciÃ³n-de-la-cinemÃ¡tica-del-sdv)
    - [3.4.1. ğŸ§¾ Pruebas iniciales](#341--pruebas-iniciales)
    - [3.4.2. ğŸ“ CaracterizaciÃ³n de motores](#342--caracterizaciÃ³n-de-motores)
    - [3.4.3. ğŸ”§Cambio en programaciÃ³n de la cinemÃ¡tica](#343-cambio-en-programaciÃ³n-de-la-cinemÃ¡tica)
    - [3.4.4. âœ… ValidaciÃ³n de la programaciÃ³n de la cinemÃ¡tica](#344--validaciÃ³n-de-la-programaciÃ³n-de-la-cinemÃ¡tica)
  - [3.5. ğŸ–¥ï¸ SimulaciÃ³n](#35-ï¸-simulaciÃ³n)
  - [3.6. ğŸ“¡ Lidar](#36--lidar)
  - [3.7. ğŸ—ºï¸ Mapa Global](#37-ï¸-mapa-global)
  - [3.8. ğŸŒ OdometrÃ­a y LocalizaciÃ³n](#38--odometrÃ­a-y-localizaciÃ³n)
    - [3.8.1. ğŸ‘£ OdometrÃ­a](#381--odometrÃ­a)
    - [3.8.2. ğŸ“ AMCL](#382--amcl)
      - [3.8.2.1. Â¿CÃ³mo Funciona?](#3821-cÃ³mo-funciona)
      - [3.8.2.2. Â¿CÃ³mo se implementa?](#3822-cÃ³mo-se-implementa)
    - [3.8.3. ğŸ”¥ Hector Mapping](#383--hector-mapping)
      - [3.8.3.1. Â¿CÃ³mo Funciona?](#3831-cÃ³mo-funciona)
      - [3.8.3.2. Â¿CÃ³mo se implementa?](#3832-cÃ³mo-se-implementa)
  - [3.9. ğŸ—ƒï¸ PlaneaciÃ³n](#39-ï¸-planeaciÃ³n)
    - [3.9.1. â­ A\*](#391--a)
    - [3.9.2. ğŸ–¥ï¸ ImplementaciÃ³n](#392-ï¸-implementaciÃ³n)
  - [3.10. ğŸ•¹ï¸ Control](#310-ï¸-control)
    - [3.10.1. â­ï¸ Pure Pursuit](#3101-ï¸-pure-pursuit)
    - [3.10.3. ğŸ–¥ï¸ ImplementaciÃ³n](#3103-ï¸-implementaciÃ³n)
- [4. ğŸ¥¼ Pruebas](#4--pruebas)
  - [Prueba con AMCL y odometria teÃ³rica](#prueba-con-amcl-y-odometria-teÃ³rica)
- [5. ğŸ§ª Resultados](#5--resultados)
- [6. ğŸ”š Conclusiones](#6--conclusiones)
- [7. ğŸ‘¨ğŸ¼â€ğŸ« Proceso de aprendizaje](#7--proceso-de-aprendizaje)
- [8. ğŸ“– Bibliografia](#8--bibliografia)

</details>

## 1. ğŸ¯ Objetivos

## 2. ğŸš— Conociendo al SDV

En el proceso de migraciÃ³n del SDVUN1 a ROS2 es necesario conocer de primera mano el funcionamiento y operaciÃ³n de los componentes del robot. Lo primero por descubrir es el rol de la Tiva en el proceso de comunicaciÃ³n entre los drivers de los motores y la NUC.
<div align="center">
<img width="700" height="463" alt="LazoControl" src="https://github.com/user-attachments/assets/863656fd-fdd0-49fb-8037-90483a1c4678" />
</div>

<div align="center">
  <img width="300"  alt="Blank diagram - Page 23" src="https://github.com/user-attachments/assets/84c4a94c-67f7-480a-b780-e1941fe37414" />
</div>

Primero iniciamos con las conexiones fisicas entre los motores y los encoders a los drivers, a continuaciÃ³n se presenta el esquema de conexiones descritas.

### 2.1. ğŸ§± Componentes implementados 

#### 2.1.1. ğŸ›ï¸ Tiva
El SDV utiliza una placa de desarrollo launchpad TIVA de National Instruments, la cual se encarga de configurar la comunicaciÃ³n entre la NUC y los motores del vehÃ­culo para la ejecuciÃ³n de un movimiento controlado, a continuaciÃ³n se presenta la imagen de la tiva que ademÃ¡s estÃ¡ montada sobre una PCB desarrollada para la hacer la conexiÃ³n por puerto SATA con los drivers de los respectivos motores:
<div align="center">
<img width="400"  alt="ConexiÃ³n" src="https://github.com/user-attachments/assets/9c5efe28-f632-4d6a-85b1-192cad82ea40" />
</div>
AdemÃ¡s, se desarrollÃ³ esta PCB que se encarga del mapeo de las conexiones en el bus SATA como se muestra a continuaciÃ³n:
<div align="center">
<img width="300"  alt="PCBEscon" src="https://github.com/user-attachments/assets/aaf3ffca-48dc-428a-867f-3db05c0106f4" />
</div>


<!---Poner informacion del LaunchPad--->

#### 2.1.2. ğŸš Driver y Encoder
El driver utilizado es un driver de EsconMotor referencia 50/5 el cual se comunica por puerto serial con la tiva, que le envÃ­a los valores de PWM para el motor que controla y se realimenta con el encoder, esta realimentaciÃ³n la usa para realizar el control de velocidad en el motor correspondiente. Tiene diferentes entradas y salidas, entre ellas una entrada para las seÃ±ales digitales del encoder y un puerto de comunicaciÃ³n con la tiva a traves de un cable SATA. 

<div align="center">
<img width="400"  alt="Conexion PCBEscon" src="https://github.com/user-attachments/assets/c97b2dc5-3c7d-4005-9fc5-ffeb69124703" />
</div>

El encoder utilizado tiene una resolucÃ³n de 1200 PPR, lo cual brinda una resoluciÃ³n mÃ¡s que suficiente para el control del motor

<div align="center">
<img width="400"  alt="Encoder" src="https://github.com/user-attachments/assets/2074c60a-afdb-44dd-bc8b-95d6504c9bb3" />
</div>


<!---Poner informacion del driver--->

#### 2.1.3. ğŸš˜ Motores
Los motores tambien son de la marca Maxon Motors, son motores DC con un sistema de engranajes que generan una reducciÃ³n de 57/1 y elevan el torque del motor. 
<div align="center">
<img width="400"  alt="Motor" src="https://github.com/user-attachments/assets/9ff65ddc-7f57-4008-aff4-1093654eaa7f" />
</div>


<!---Poner informacion de los motores--->

#### 2.1.4. ğŸ§  NUC
El procesamiento en general corre sobre una Intel NUC que posee un procesador Core I7 con 8 NÃºcleos, 8 GB de memoria Ram y un SSD SATA de 240 GB, se conecta a la red local a travÃ©s de la red WIFI de laboratorio.
<div align= "center">
<img width="400"  alt="NUC" src="https://github.com/user-attachments/assets/814236b2-b625-4bf7-a34b-7d7d41c1503f") />
</div>

<!---Poner informacion de la NUC y sus caracteristicas de hardware--->

#### 2.1.5. ğŸ“¶ Lidar
El lidar implementado es un Sick Nav 350-3232 el cual tiene una capacidad de detecciÃ³n de 360Â° se alimenta con 2 BaterÃ­as LiPo de 4 celdas cada una y se conecta a la NUC a traves del puerto Ethernet, es necesario mencionar que la IP del adaptador de Red debe estÃ¡r en el mismo rango de IP que el LiDar ya que una mala configuraciÃ³n no permite que se inicie la comunicaciÃ³n entre el LiDar y la NUC
<!--Informacion general del lidar-->
<div align= "center">
<img width="400" height="547" alt="LiDar" src="https://github.com/user-attachments/assets/1c6af9ea-e131-40e6-aec6-217a148aaa9f")/>
</div>

## 3. ğŸ”¢ Procedimiento

### 3.1. ğŸ—ï¸ Arquitectura en ROS Melodic

Se quiere comprender el funcionamiento inicial del robot con la arquitectura realizada previamente por el grupo DIMA fue implementada en ROS Melodic 1.14.12. Para ello se analizan los nodos y tÃ³picos implementados, para obtener una visiÃ³n general de la arquitectura, se muestran a continuaciÃ³n en el grafo RQT.

<div align="center">
<img width="2960" height="1224" alt="Group" src="https://github.com/user-attachments/assets/19fe4194-843f-41f9-9f89-4250225912e9" />
</div>

**Nota:** Esta arquitectura se encuentra bajo derechos de autor por lo cual no puede ser compartida en su totalidad.

Los nodos y su descripciÃ³n general se pueden comprender en la siguiente tabla:

A partir de esto, se puede decir que:

* Existe un nodo dedicado a la comunicaciÃ³n con la Tiva.
* Se emplea el paquete oficial de ROS "*move_base*" para la navegaciÃ³n.
* Se utiliza Hector Mapping para el SLAM.
* Hay nodos dedicados a la comunicaciÃ³n en red y con Firebase.
* Existen nodos exclusivos para el uso del Lidar.
  
Teniendo en cuenta lo anterior se decidiÃ³ empezar con la actualizaciÃ³n a ROS2 de las siguientes caracterÃ­sticas:

* ComunicaciÃ³n serial a la Tiva
* NavegaciÃ³n con "*Nav2*" de ROS2 ("*Move Base*" no existe para ROS2)
* Uso de Lidar con paquetes oficiales de SICK

Cabe aclarar que se tiene acceso a los archivos originales de los SDV por lo cual se puede reutilizar archivos de declaraciones (en C++) y simulaciones (con archivos DAE).

### 3.2. ğŸ’» Firmware de Tiva

para acceder al firmware de la tiva se ejecuta el siguiente comando

```bash
screen /dev/ttyACM0 921600
```

**Nota:** Se debe tener instalado "screen" (ejecutar ```sudo apt install screen```)

dentro de screen se envia el comando ```h``` para poder revisar la informaciÃ³n de los comandos disponibles para usarlo

<div align="center">

<img width="591" height="547" alt="Screenshot_2025-10-30_09-59-37" src="https://github.com/user-attachments/assets/237ad5b4-42c9-4e8d-95d9-b5fc4b87f575" />

</div>

Aca se puede observar los deversos comandos que se pueden enviar a la tiva, el necesario para el uso de los motores es ```m``` con los argumentos de habilitaciÃ³n y velocidades con signo de cada motor. Con ello se concluye que:

* al enviar ```m 1 +V1 +V2``` los motores se habilitan y giran en sentido que avance el robot
* al enviar ```m 0 +/-V1 +/-V2``` los motores se deshabilitan y el robot se detiene
* Las velocidades que se envian tiene en cuenta el marco de referencia del robot ($+x$ en sentido de avance) mas no el marco de referencia de cada rueda ($+z$ saliendo de la rueda, provocando que la rueda derecha deba girar en sentido negativo a este marco para lograr avance lineal)

### 3.3. ğŸ¤– Arquitectura en ROS2 Humble

Una vez se comprendiÃ³ la comunicaciÃ³n entre la NUC y la tiva para el envio de comandos al driver de los motores se procediÃ³ con la actualizaciÃ³n de los nodos descritros en [Arquitectura en ROS Noetic](#ï¸-arquitectura-en-ros-noetic). AcontinuaciÃ³n se describen los nodos actualizados

* **_SDV_Serial:_**  Permite la comunicaciÃ³n con la Tiva por medio del puerto serial. Los comandos enviados siguen la tabla descrita en la secciÃ³n [Firmware de Tiva](#-firmware-de-tiva).
* **_SDV_Control:_**  Realiza la cinematica inversa del robot, por medio de la transformaciÃ³n de las velocidades lineales y angulares a valores PWM para cada rueda. Para mayor informaciÃ³n ir a 
### 3.4. âš™ï¸ ProgramaciÃ³n de la CinemÃ¡tica del SDV

#### 3.4.1. ğŸ§¾ Pruebas iniciales

Para comprobar el correcto funcionamiento del robot, se verificÃ³ la cinematica implementada en la version inicial (Con ROS noetic) para ello se tomÃ³ un video enviadole una velocidad lineal de $0.1\tfrac{m}{s}$ y se procesÃ³ con Tracker

<div align="center">
<img width="700"  alt="Lineal_previo_Tracker" src="https://github.com/user-attachments/assets/fc5f697a-1fa2-445c-abf7-4f3b6a6b87b4" />
</div>

Al realizar el analisis con los datos recolectados con el programa dio un promedio de $0.06\tfrac{m}{s}$ dando un error absoluto en la velocidad lineal de aproximadamente 40%. Teniendo en cuenta esto, no se realizÃ³ la prueba angular y se siguiÃ³ con la caracterizaciÃ³n de los motores y la implementaciÃ³n de una nueva cinemÃ¡tica.

<!-- colocar el codigo o la ecuacion que habian empleado-->

#### 3.4.2. ğŸ“ CaracterizaciÃ³n de motores

Para este proceso se enviaron valores de PWM a la tiva iniciando en 20 y en paso de 10 hasta 60 y se contÃ³ el nÃºmero de revoluciones para mismos periodos de tiempo en cada prueba como se muestra en el siguiente video:

<div align ='center'>
   <video src='https://github.com/user-attachments/assets/3671fbed-32fd-4de0-80da-c60e88005442'>
</div>

A partir de la informaciÃ³n obtenida se elaborÃ³ la siguiente tabla que muestra los valores obtenidos:
<div align ='center'>
   
| % PWM | RPM RUEDAS | 
|    :---:     |     :---:     |  
| 20   | 2    | 
| 30   | 4    | 
| 40   | 6    |
| 50   | 8    |
| 60   | 10   |

</div>

<!---Colocar la regresiÃ³n lineal-->

$$\text{RPM} = 1.2\text{PWM}-12$$

Cabe resaltar que se asume que la ganacia lineal y desface de los motores para generar torque es aproximadamente igual en ambos sentidos de giro

#### 3.4.3. ğŸ”§Cambio en programaciÃ³n de la cinemÃ¡tica

Con la regresion lineal hallada en la [CaracterizaciÃ³n de motores](#-caracterizaciÃ³n-de-motores) se implementÃ³ en el cÃ³digo teniendo las siguientes consideraciones:

- La velocidad enviada por el tÃ³pico serÃ¡ en metros por segundo $m/s$
- La conversion debe ser a PWM y se debe tener en cuenta que la regresion es PWM $vs$ RPM
- Al considerarse igualdad en la ganancia en ambos sentidos de giro se debe tomar el valor absoluto de la velocidad y solo cambia el signo para aplicar el cambio de giro

Por lo cual la ecuaciÃ³n cambia a

$$\text{PWM} = 0.8333(\tfrac{30}{\pi})|v_{\text{rueda}}| + 10$$

Dicha ecuaciÃ³n se implementÃ³ en el cÃ³digo como se observa acontinuaciÃ³n:

```cpp
int getPWM(double V, double W,bool Side){
        /*Function to get PWM for each wheel 
        <args>
        V -> Lineal Velocity
        W -> Angular Velocity
        Side -> Side of wheel (True: Right | False: Left)
        */
        double wheel_radio = 0.075; //radio of wheels in meters
        double wheel_base = 0.32;  //distance between wheel (RL) in meter
        int factor = 0;

        double w_wheel =  V/wheel_radio;

        if(Side){
            w_wheel -= (wheel_base*W)/wheel_radio; 
        }else{
            w_wheel += (wheel_base*W)/wheel_radio;
        };

        if(w_wheel>0){
        factor = 1;
        }else{
        factor = -1;
        };

        return (0.8333*(30/3.141592)*abs(w_wheel)+10)*factor;
    }
```

#### 3.4.4. âœ… ValidaciÃ³n de la programaciÃ³n de la cinemÃ¡tica

Una vez cambiada la cinematica implementada, se verificÃ³ la velocidad lineal y angular, para ello se tomaron videos y se procesaron con el sofware Tracker

<div style="text-align: center;">
  <img src="https://github.com/user-attachments/assets/30ef1ca8-a4df-4e1f-a082-2f067486d7b9" 
       alt="Lineal_Tracker" width="45%" style="display: inline-block; margin-right: 10px;" />
  <img src="https://github.com/user-attachments/assets/1cafe035-001f-4ff1-9eef-9d4a9bfb6a33" 
       alt="Angular_Tracker" width="45%" style="display: inline-block;" />
</div>

Dando como resultado:

<div align ='center'>

|Velocidad|Enviada|Medida|Error|
|---|----|---|---|
|Lineal ($v$)|$0.1\tfrac{m}{s}$|$0.09\tfrac{m}{s}$|$7$%|
|Angular ($\omega$)|$0.5\tfrac{rad}{s}$|$0.43\tfrac{rad}{s}$|$13$%|

</div>

### 3.5. ğŸ–¥ï¸ SimulaciÃ³n

Para la simulaciÃ³n se emplearon los archivos base de Gazebo desarrollados previamente, acotÃ¡ndolos especÃ­ficamente para el SDV 1, ya que para cada SDV cambian ciertas caracterÃ­sticas tÃ©cnicas y fÃ­sicas. Estos archivos de lanzamiento fueron actualizados a ROS 2, debido a que en esta versiÃ³n ya no se utilizan archivos de tipo YML, sino que los parÃ¡metros deben declararse dentro de los propios archivos de lanzamiento.

En el desarrollo original existÃ­an diversos parÃ¡metros para cada SDV, tanto generales como especÃ­ficos, por lo que fue necesario comprender la estructura de los archivos URDF para lograr el correcto ensamble del robot en Gazebo. AdemÃ¡s, se actualizÃ³ la declaraciÃ³n correspondiente para emplear el mapa del laboratorio.

A continuaciÃ³n, se presenta el modelo CAD del robot y del entorno del laboratorio en Gazebo:

<div align="center">
<img width="882" height="643" alt="image" src="https://github.com/user-attachments/assets/e7bf0597-9bf4-4f9b-954e-439f32685df2" />
</div>

TambiÃ©n se considerÃ³ el uso del software NVIDIA Isaac Sim para la simulaciÃ³n robÃ³tica; sin embargo, este producto requiere amplias capacidades de cÃ³mputo, por lo cual no ha sido posible su implementaciÃ³n.

Por otra parte, se crearon las dependencias necesarias para la transformaciÃ³n de marcos de referencia (tf) con el fin de visualizar el robot en RViz. A continuaciÃ³n, se muestra su visualizaciÃ³n en dicho programa:

<div align="center">
<img width="882" height="643" alt="image" src="https://github.com/user-attachments/assets/27942275-2cc4-40c5-97e7-a8b4f41ea8b4" />
</div>

**Nota:** En RViz Ãºnicamente se muestra el robot, ya que las transformaciones tf solo se aplican al modelo del robot y no al mapa.

### 3.6. ğŸ“¡ Lidar

Para conectar el lidar, se emplea el software oficial *SOPAS_ET*. En primer lugar se verifica la IP asignada al Lidar para su conexiÃ³n, como se puede ver acontinuaciÃ³n:

<div align="center">
<img width="402" height="586" alt="SOPAS_IP" src="https://github.com/user-attachments/assets/1bb77ef5-e4bc-4f0c-9c7d-7a5f5b60fa0c" />

</div>

Quedando asignada la IP "169.254.7.16". Ya con esto se verifica el modo de operaciÃ³n del Lidar que debe ser NavegaciÃ³n para poder emplear su capacidad de mapeo y de odometria, en la siguiente imagen se puede observar el mapeo con el programa

<div align="center">
<img width="1366" height="730" alt="SOPAS_Nav" src="https://github.com/user-attachments/assets/bf68d156-fd40-4b27-8c28-6c06eb0a972a" />
</div>

una vez verificado se siguiÃ³ el procedimiento del paquete oficial para ROS2 creado por el fabricante ([sick_scan_xd](https://docs.ros.org/en/iron/p/sick_scan_xd/)), dicho paquete fue incluido en el _workspace_ y se eliminaron los archivos no necesarios. Una vez con este paquete fue necesario realizar cambios en el archivo "_sick_nav_350.launch_" puesto que la IP que trae por defecto el Lidar fue modificada para evitar que se pueda acceder directamente desde WiFi

```python
<arg name="hostname" default="169.254.7.16"/>
```

Aparte de esto es necesario recalcar que se debe cambiar la IP del puerto Ethernet (Eth0) de la NUC a "169.254.7.15" para poder realizar la comunicaciÃ³n con el Lidar. Al cambiar las IPs se realiza Ping al Lidar para comprobar la comunicaciÃ³n. Ya con esta verificaciÃ³n se puede realizar el compilado, el cual la primera vez que se ejecute se debe realizar de la siguiente manera

```bash
colcon build --packages-select sick_scan_xd --cmake-args " -DROS_VERSION=2" " -DLDMRS=0" --event-handlers console_direct+
. install/setup.bash
```

Esto con el fin de que se instalen las dependencias necesarias para su correcto funcionamiento. Al terminal al compilacion se realiza el lanzamiento de los nodos 

```bash
ros2 launch sick_scan_xd sick_nav_350.launch.py
```

dichos nodos permiten la comunicaciÃ³n con el Lidar y la habilitaciÃ³n del topico ```/scan``` el cual manda mensajes de tipo ```sensor_msgs/msg/LaserScan```  para visualizar el funcionamiento del Lidar una vez estÃ© conectado a ROS2, se puede ejecutar RViz2 como se ve acontinuaciÃ³n:

<div align="center">
<img width="1919" height="1076" alt="Screenshot from 2025-10-30 10-21-09" src="https://github.com/user-attachments/assets/f12cae8f-1e4e-4693-9c63-7cb3fb104eda" />
</div>

Aca se puede ver el entorno que el lidar puede percibir

### 3.7. ğŸ—ºï¸ Mapa Global

El mapa global generado previamente por medio de SLAM con el SDV y el Lidar en la versiÃ³n base se puede ver en [](). Para implementarlo en ROS2 se usa **map_server** de **Nav2**, este nodo toma el archivo **.yaml** y genera el tÃ³pico ```\map``` para poder consultar el mapa global cuando se requiera. En la siguiente imagen se puede ver el mapa global del laboratorio LabFabEx:

### 3.8. ğŸŒ OdometrÃ­a y LocalizaciÃ³n

Para que el robot pueda navegar en un entorno, es necesario determinar de manera dinÃ¡mica su posiciÃ³n dentro del mapa. Inicialmente se empleÃ³ la LocalizaciÃ³n Adaptativa de Monte Carlo (AMCL, por sus siglas en inglÃ©s). Sin embargo, debido a que el robot no cuenta con encoders disponibles para la lectura de odometrÃ­a real, se decidiÃ³ cambiar a Hector Mapping, que permite obtener tanto la odometrÃ­a como la localizaciÃ³n utilizando Ãºnicamente el LIDAR.
A continuaciÃ³n, se describen ambos enfoques.

#### 3.8.1. ğŸ‘£ OdometrÃ­a

Para la odometrÃ­a, inicialmente se empleÃ³ una odometrÃ­a teÃ³rica, es decir, a partir de los comandos de velocidad que recibirÃ­a el robot ($\dot{\theta}_r$ y $\dot{\theta}_l$) y una pose inicial, se calculaba en cada instante de tiempo la posiciÃ³n del robot mediante las fÃ³rmulas estÃ¡ndar de movimiento rectilÃ­neo y curvilÃ­neo.
Para implementarlo, se desarrollÃ³ un algoritmo basado en el siguiente pseudocÃ³digo:

```cpp
funciÃ³n update_odometry():

    ahora = tiempo_actual()
    dt = ahora - tiempo_anterior

    si dt <= 0 o dt > 1:
        tiempo_anterior = ahora
        terminar funciÃ³n

    tiempo_anterior = ahora

    // 1. Calcular velocidades lineales de cada rueda
    v_r = R * dot_theta_r
    v_l = R * dot_theta_l

    // 2. Velocidad lineal y angular del robot
    v = (v_r + v_l) / 2
    w = (v_r - v_l) / L

    // 3. IntegraciÃ³n de pose
    si |w| es muy pequeÃ±o:
        // Movimiento recto
        x  = x + v * cos(th) * dt
        y  = y + v * sin(th) * dt
    si no:
        // Movimiento curvo
        x = x + (v / w) * (sin(th + w*dt) - sin(th))
        y = y - (v / w) * (cos(th + w*dt) - cos(th))

    th = th + w * dt

    // Normalizar Ã¡ngulo a [-Ï€, Ï€]
    mientras th >  Ï€: th = th - 2Ï€
    mientras th < -Ï€: th = th + 2Ï€

    pose = (x, y, th)
```

Que siguen las siguientes ecuaciones, velocidades:

$$v_r = R\,\dot{\theta}_r$$
$$v_l = R\,\dot{\theta}_l$$

Con $R$ como radio de la rueda. Movimiento rectilinio ($\omega<\epsilon$):

$$x_t = x_{t-1} + v \cos(\theta_{t-1})\,\Delta t$$
$$y_t = y_{t-1} + v \sin(\theta_{t-1})\,\Delta t$$

movimiento curvilineo ($\omega>\epsilon$):

$$x_t = x_{t-1} + \frac{v}{\omega}\left[\sin(\theta_{t-1}+\omega\Delta t) - \sin(\theta_{t-1})\right]
$$
$$y_t = y_{t-1} - \frac{v}{\omega}\left[\cos(\theta_{t-1}+\omega\Delta t) - \cos(\theta_{t-1})\right]$$

$$\theta_t = \theta_{t-1} + \Delta\theta$$

Es importante destacar que, al ser un modelo teÃ³rico, se asumen movimientos ideales: sin deslizamiento, sin pÃ©rdidas de potencia en los motores, sin inercia, con cambios instantÃ¡neos de velocidad (sin rampas de aceleraciÃ³n/desaceleraciÃ³n), entre otras simplificaciones.

#### 3.8.2. ğŸ“ AMCL

##### 3.8.2.1. Â¿CÃ³mo Funciona?

AMCL es un mÃ©todo de localizaciÃ³n basado en filtros de partÃ­culas. Mantiene un conjunto de hipÃ³tesis (partÃ­culas) sobre la posible posiciÃ³n del robot en el mapa. Cada vez que el robot se mueve, estas partÃ­culas se actualizan segÃºn el modelo de movimiento (odometrÃ­a).
Al recibir mediciones del sensor lÃ¡ser, el algoritmo compara estas mediciones con el mapa y ajusta el peso de cada partÃ­cula segÃºn la coincidencia observada. Finalmente, emplea un proceso de resampling para concentrarse en las partÃ­culas mÃ¡s probables, logrando una estimaciÃ³n robusta incluso en presencia de ruido.

##### 3.8.2.2. Â¿CÃ³mo se implementa?

Para implementar AMCL en ROS se utiliza principalmente la odometrÃ­a del robot, el mapa estÃ¡tico, el LIDAR y una pose inicial. En este proyecto, la pose inicial se definiÃ³ en un punto home ($x=0$, $y=0$) con una orientaciÃ³n predeterminada ($\omega=0$); sin embargo, dicha pose puede configurarse desde **RViz** o desde un nodo externo mediante el tÃ³pico ```\InitialPose```.

Se emplean los siguientes tÃ³picos:
* ```\odom``` odometria del robot (Ver mas en [OdometrÃ­a](#381--odometrÃ­a))
* ```\scan``` datos del Lidar (Ver mas en [Lidar](#36--lidar))
* ```\map``` Mapa estÃ¡tico (Ver mas en [Mapa Global](#37-ï¸-mapa-global))

#### 3.8.3. ğŸ”¥ Hector Mapping

##### 3.8.3.1. Â¿CÃ³mo Funciona?

Hector Mapping es un algoritmo de SLAM 2D diseÃ±ado para operar Ãºnicamente con datos de un sensor lÃ¡ser, sin necesidad de odometrÃ­a ni IMU. Utiliza un enfoque basado en scan matching, alineando cada escaneo del LIDAR con el mapa que se construye en tiempo real.

Para esto emplea un mÃ©todo de Gradient Descent sobre un mapa de ocupaciÃ³n tipo grid map, buscando la pose que produce la mejor coincidencia entre el escaneo actual y la estructura del entorno ya mapeada. Este proceso se realiza continuamente, lo que permite obtener localizaciÃ³n precisa incluso sin encoders.

Gracias a esta estrategia, Hector Mapping resulta especialmente Ãºtil en robots con buenos sensores lÃ¡ser pero sin odometrÃ­a confiable, entregando una estimaciÃ³n estable y fluida Ãºnicamente a partir de los datos del LIDAR.

##### 3.8.3.2. Â¿CÃ³mo se implementa?

Para implementar Hector Mapping en ROS se utiliza principalmente el tÃ³pico del LIDAR (```/scan```) para realizar el scan matching y construir el mapa dinÃ¡mico.
A diferencia de AMCL, Hector Mapping no requiere odometrÃ­a, aunque puede usarla opcionalmente si estÃ¡ disponible.

El algoritmo publica la pose estimada del robot y genera un mapa dinÃ¡mico mientras opera, por lo que en este proyecto cumple simultÃ¡neamente el rol de odometrÃ­a y localizaciÃ³n, permitiendo la navegaciÃ³n sin encoders ni modelos de movimiento precisos.

### 3.9. ğŸ—ƒï¸ PlaneaciÃ³n

#### 3.9.1. â­ A*

#### 3.9.2. ğŸ–¥ï¸ ImplementaciÃ³n

### 3.10. ğŸ•¹ï¸ Control

#### 3.10.1. â­ï¸ Pure Pursuit

#### 3.10.3. ğŸ–¥ï¸ ImplementaciÃ³n

## 4. ğŸ¥¼ Pruebas

### Prueba con AMCL y odometria teÃ³rica

Como prueba inicial, se evaluÃ³ el robot utilizando AMCL junto con una odometrÃ­a teÃ³rica, tal como se describe en la secciÃ³n [OdometrÃ­a y LocalizaciÃ³n](#38--odometrÃ­a-y-localizaciÃ³n). Para ello, se configurÃ³ RViz2 para visualizar en tiempo real los principales tÃ³picos de ROS (pose actual, goal, odometrÃ­a, TFs, etc.) y compararlos con el comportamiento fÃ­sico del robot. 

Durante las pruebas, se enviaron dos goals distintos con el fin de analizar la respuesta del sistema y observar si la localizaciÃ³n se mantenÃ­a estable. Las ejecuciones pueden verse a continuaciÃ³n:

En la mayorÃ­a de los casos, el robot presentaba comportamientos incorrectos: ya fuera porque se perdÃ­a y comenzaba a realizar movimientos errÃ¡ticos, o porque detenÃ­a su avance antes de tiempo, dado que el sistema estimaba de forma equivocada que ya habÃ­a alcanzado el objetivo cuando en realidad todavÃ­a estaba lejos de Ã©l.

## 5. ğŸ§ª Resultados

## 6. ğŸ”š Conclusiones

## 7. ğŸ‘¨ğŸ¼â€ğŸ« Proceso de aprendizaje

## 8. ğŸ“– Bibliografia

